{"cells":[{"cell_type":"markdown","source":["## Import useful Python packages"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52d4c736-ea3a-4d37-bfa9-da2a728a3d1c"}}},{"cell_type":"code","source":["import requests\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark import SparkContext, SparkConf"],"metadata":{"id":"Fh8zPg5APmYv","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbf07d9e-5f94-4e80-8d2e-8f3026d8e736"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Check everything is ok"],"metadata":{"id":"_eRvyl2xwCV6","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1368fd6b-88a4-4e6f-8091-479e4e71bcf1"}}},{"cell_type":"code","source":["spark"],"metadata":{"id":"4fqJ5f0JE3BL","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2dad3bf-ea7f-4655-8761-cf3d0785d5ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["sc._conf.getAll()"],"metadata":{"id":"qhTN342EEOYZ","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"957f646f-aff9-42a0-b846-3a00e1fe906e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **The Prediction Task**\n\nIn this notebook, we will be using a dataset from [Kaggle](https://www.kaggle.com/rouseguy/bankbalanced/data) containing a _balanced_ random sample of **11,162 instances** extracted from the original (_unbalanced_) dataset of 45,211 examples, available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing).\n\nThe dataset is related with direct marketing campaigns (i.e., phone calls) of a Portuguese banking institution. Each record (**x**, _y_) contains customer information represented by means of **16 features** (i.e., **x** = _x1_, ..., _x16_), along with a **binary response** (_y_), which indicates whether the given customer subscribes (_y_ = 1) or not (_y_ = 0) the term deposit proposed by the phone marketing campaign.\n\nThe classification goal is, given a _new_ customer, to predict if she/he will subscribe a term deposit."],"metadata":{"id":"Mu77QbD2vC_o","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c31d271-4a99-4022-b1a1-2f58fbd45e92"}}},{"cell_type":"markdown","source":["## **1. Data Acquisition**\n\nThis is the first step we need to accomplish before going any further. The dataset will be downloaded and loaded to DBFS, as usual."],"metadata":{"id":"g-vLczwIuUhG","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b02be78d-06a6-4581-9fca-19487e3c5656"}}},{"cell_type":"markdown","source":["### Download the dataset to the local driver node's ```/tmp``` folder using ```wget```"],"metadata":{"id":"j5fI3wiGvKBl","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b85ca7d2-da3c-4c70-9895-6f4bfff21073"}}},{"cell_type":"code","source":["%sh wget -P /tmp https://github.com/gtolomei/big-data-computing/raw/master/datasets/bank-marketing.csv.bz2"],"metadata":{"id":"kxrLDE_4e7KH","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0af62ac7-a60c-48cb-8cbf-0e95320cf209"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls file:/tmp/"],"metadata":{"id":"quiuGbfyv8vT","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e71ad0d-ef33-4bec-bd31-5a69c81b5fbe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Move the file from local driver node's file system to DBFS"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75f0ffa8-1ae9-487a-bd08-652706e508ad"}}},{"cell_type":"code","source":["dbutils.fs.mv(\"file:/tmp/bank-marketing.csv.bz2\", \"dbfs:/bdc-2020-21/datasets/bank-marketing.csv.bz2\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5727f852-ff7a-468c-b992-9dbc0ea42648"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls /bdc-2020-21/datasets/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a400643-ab88-401b-8d02-5e5c1f11e788"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Read dataset file into a Spark Dataframe**"],"metadata":{"id":"DevlrMcPw1ZI","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7588e71d-82d2-4b70-a67f-f87ec5e05fae"}}},{"cell_type":"code","source":["bank_df = spark.read.load(\"dbfs:/bdc-2020-21/datasets/bank-marketing.csv.bz2\", \n                         format=\"csv\", \n                         sep=\",\", \n                         inferSchema=\"true\", \n                         header=\"true\"\n                         )"],"metadata":{"id":"qKi5Hd60FFcX","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9118fa5e-12ac-44e3-9728-97bc7c6764ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Check the shape of the loaded dataset, i.e., number of rows and columns**"],"metadata":{"id":"IPTd8ep9x74H","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98c32312-2214-4b25-8e7c-71d568d328a6"}}},{"cell_type":"code","source":["print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(bank_df.count(), len(bank_df.columns)))"],"metadata":{"id":"JyRyYqeXGA4l","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af5c61bf-2b18-46cd-8fdc-3fe3e90d5b3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Print out the schema of the loaded dataset**"],"metadata":{"id":"-WC4RPQgyEsB","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7da40297-6fc9-4e7a-a05c-95b71bed622a"}}},{"cell_type":"code","source":["bank_df.printSchema()"],"metadata":{"id":"Q3KhtSnvGIwG","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3db45bc7-b568-46b0-95e1-b22517045fca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Dataset Shape and Schema**\n\nThe dataset contains **11,162** records of marketing campaigns; each record, is represented by the following set of **17** columns:\n- `age`: The customer's age (_numerical_, _discrete_);\n- `job`: The customer's type of job (_categorical_, _nominal_: \"`admin.`\", \"`blue-collar`\", \"`entrepreneur`\", \"`housemaid`\", \"`management`\", \"`retired`\", \"`self-employed`\", \"`services`\", \"`student`\" \"`technician`\", \"`unemployed`\", \"`unknown`\");\n- `marital`: The customer's marital status (_categorical_, _nominal_: \"`divorced`\", \"`married`\", \"`single`\", \"`unknown`\") [**NOTE:** \"`divorced`\" means divorced or widowed];\n- `education`: The customer's level of education (_categorical_, _ordinal_: \"`basic.4y`\", \"`basic.6y`\", \"`basic.9y`\", \"`high.school`\", \"`illiterate`\", \"`professional.course`\", \"`university.degree`\", \"`unknown`\");\n- `default`: Indicates if the customer has credit in default (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n- `balance`: The customer's average yearly balance in Euro (_numerical_, _continuous_);\n- `housing`: Indicates if the customer has a housing loan (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n- `loan`: Indicates if the customer has a personal loan (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n- `contact`:  The customer's contact medium type (_categorical_, _nominal_: \"`cellular`\", \"`telephone`\");\n- `day`: Last contact day of the month (_numerical_, _discrete_: ranging from `1` to `31`);\n- `month`: Last contact month of year (_categorical_, _nominal_: \"`jan`\", \"`feb`\", \"`mar`\", ..., \"`nov`\", \"`dec`\");\n- `duration`: Last contact duration, in seconds (_numerical_, _continuous_). [**NOTE:** This attribute highly affects the output target (e.g., if `duration = 0` then `deposit = \"no\"`). Yet, the duration is not known before a call is performed. Also, after the end of the call `deposit` is obviously known. Thus, this feature should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.]\n- `campaign`: The number of contacts performed during this campaign and for this customer (_numerical_, _discrete_) [**NOTE:** includes last contact];\n- `pdays`: The number of days that passed by after the client was last contacted from a previous campaign (_numerical_, _discrete_) [**NOTE:** `999` means client was not previously contacted];\n- `previous`: The number of contacts performed before this campaign and for this client (_numerical_, _discrete_);\n- `poutcome`: The outcome of the previous marketing campaign (_categorical_, _nominal_: \"`failure`\", \"`nonexistent`\", \"`success`\");\n- **`deposit`**: Indicates if the customer subscribed a term deposit (_categorical_, _nominal_: \"`yes`\", \"`no`\") **[This is the _binary target_ variable we want to predict]**."],"metadata":{"id":"dXlcRfzmNNCv","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b105c8ab-bdb4-4094-8eb9-1e8543e057f3"}}},{"cell_type":"code","source":["# Let's define some constants which we will use throughout this notebook\nNUMERICAL_FEATURES = [\"age\", \n                      \"balance\",\n                      \"day\",\n                      \"duration\",\n                      \"campaign\",\n                      \"pdays\",\n                      \"previous\"\n                      ]\nCATEGORICAL_FEATURES = [\"job\", \n                        \"marital\", \n                        \"education\", \n                        \"default\", \n                        \"housing\",\n                        \"loan\",\n                        \"contact\",\n                        \"month\",\n                        \"poutcome\"\n                        ]\nTARGET_VARIABLE = \"deposit\""],"metadata":{"id":"xsHSUHEzDS1-","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b161c11-7855-4743-9410-7a3e12a35c4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"{:d} Numerical features = [{:s}]\".format(len(NUMERICAL_FEATURES), \", \".join([\"`{:s}`\".format(nf) for nf in NUMERICAL_FEATURES])))\nprint(\"{:d} Categorical features = [{:s}]\".format(len(CATEGORICAL_FEATURES), \", \".join([\"`{:s}`\".format(nf) for nf in CATEGORICAL_FEATURES])))\nprint(\"1 Target variable = `{:s}`\".format(TARGET_VARIABLE))"],"metadata":{"id":"pME8ArdkEt_M","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49ef657c-9111-49aa-944e-6e2c84a8580e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Display the first 5 rows of the dataset**"],"metadata":{"id":"0Pjib1fiylb6","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74fba4f4-f8d3-4589-bc9d-23caf6e1237d"}}},{"cell_type":"code","source":["bank_df.show(5)"],"metadata":{"id":"a4v-Z92rGXoe","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0822385b-4b93-472e-a767-c7e9e1b69409"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Check for any missing values**"],"metadata":{"id":"1Df7cSAKmqQi","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9598ec74-7cce-4617-b6bd-4ad8c22e8fe4"}}},{"cell_type":"code","source":["for c in bank_df.columns:\n  print(\"N. of missing values of column `{:s}` = {:d}\".format(c, bank_df.where(col(c).isNull()).count()))"],"metadata":{"id":"ubkWy6w6mtvG","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd8d8197-8576-4fc3-b7d7-9c85977f9e12"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **2. Data Exploration**"],"metadata":{"id":"DHTM4wS2ztOJ","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d544bca-46ca-4929-b6f5-0b64fc5c8b97"}}},{"cell_type":"markdown","source":["### **Summary of Descriptive Statistics**"],"metadata":{"id":"9TKWRYgl3jPi","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63d4cd02-2c7d-4156-9e2b-a141b5b0f89a"}}},{"cell_type":"code","source":["bank_df.describe().toPandas().transpose() # Transpose will allow a better visualization"],"metadata":{"id":"FvTv38i73pVh","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5de152e-efc1-49bf-b886-560c2c93d173"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# To access plotting libraries, we need to first transform our PySpark DataFrame into a Pandas DataFrame\nbank_pdf = bank_df.toPandas() "],"metadata":{"id":"CK1VjwrvN4BV","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b4241c9-ebed-4a62-a9d8-24925b2c6927"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Set some default plotting configuration using seaborn properties\nsns.set_style(\"darkgrid\")\nsns.set_context(\"notebook\", rc={\"lines.linewidth\": 2, \n                                \"xtick.labelsize\":14, \n                                \"ytick.labelsize\":14,\n                                \"axes.labelsize\": 18,\n                                \"axes.titlesize\": 20,\n                                })"],"metadata":{"id":"okVR9377jPTf","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4aede8f6-cf83-42ef-bf3e-f29fa3fc22c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Analysis of Data Distributions: Numerical Features**"],"metadata":{"id":"DlRGHd9WOr5i","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7c45d0e-ae05-4e45-bd3d-73332070855c"}}},{"cell_type":"markdown","source":["### 1. Distributions of individual numerical features"],"metadata":{"id":"OhurS5pHdoQK","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17c30f27-fc8e-4d21-b5d9-65d40fddb5da"}}},{"cell_type":"code","source":["# Plot the distribution of values of each column of interest\nn_rows = 4\nn_cols = 2\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(14,20))\n\nfor i,f in enumerate(NUMERICAL_FEATURES):\n    _ = sns.distplot(bank_pdf[f],\n                    kde_kws={\"color\": \"#ca0020\", \"lw\": 1}, \n                    hist_kws={\"histtype\": \"bar\", \"edgecolor\": \"k\", \"linewidth\": 1,\"alpha\": 0.8, \"color\": \"#92c5de\"},\n                    ax=axes[i//n_cols, i%n_cols]\n                    )\n\nfig.delaxes(axes[3][1]) # Remove the last cell of the plot\n\nfig.tight_layout(pad=1.5)"],"metadata":{"id":"8esOySR-Oh1Q","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bcb1b7f0-988f-46b1-b6a4-ff9b42ec0224"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Pairwise regression plots"],"metadata":{"id":"i5ZGhb9NdzgS","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bfdc47e7-019c-425e-9b07-4dd7cca608db"}}},{"cell_type":"code","source":["# Let's now plot the pairwise relationship between our numerical features\n_ = sns.pairplot(data=bank_pdf, \n                 vars=sorted(NUMERICAL_FEATURES), \n                 hue=TARGET_VARIABLE, \n                 kind=\"reg\",\n                 diag_kind='hist',\n                 diag_kws = {'alpha':0.55, 'bins':20},\n                 markers=[\"o\", \"s\"]\n                )"],"metadata":{"id":"Af5ThlVWbOry","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e88cf59a-fd92-45f2-a6e5-3c46b8dcddd9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Observations**\n\nIt is quite evident that there is no highly correlation between numeric features. Therefore, we will initially keep all of them for the model. Note that the feature `day` does not seem really informative (i.e., it is kind of uniformly distributed across all of its values for customers who both decide to opt for a deposit and for those who don't)."],"metadata":{"id":"tJABTcqqKZa8","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"480518e5-8e73-4ad9-b63a-3e44023f8d09"}}},{"cell_type":"markdown","source":["### **Analysis of Data Distributions: Categorical Features**"],"metadata":{"id":"SHB3xBzKjGui","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54d6db94-065a-44f3-b162-b54cb6e001dd"}}},{"cell_type":"markdown","source":["### 1. Histograms of individual categorical features"],"metadata":{"id":"-TKUbjOPmPkE","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6c35282-fd1f-47c5-a863-43f12ceef8a3"}}},{"cell_type":"code","source":["# For categorical variables, 'countplot' is the way to go\n# Create a Figure containing 3x3 subplots\nn_rows = 3\nn_cols = 3\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(14,14))\n\nfor i,f in enumerate(sorted(CATEGORICAL_FEATURES)): \n    ax = sns.countplot(bank_pdf[f], ax=axes[i//n_cols, i%n_cols])\n    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n\nfig.tight_layout(pad=1.5)"],"metadata":{"id":"d2MARb4wkMOP","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c82af869-51b6-41ae-8d65-a0ea1397e5f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Relationship between _categorical_ features and the _target variable_ (`deposit`)"],"metadata":{"id":"b0n4l939pdN-","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f26ef09-5aa9-4f49-bc1e-4687d1e72116"}}},{"cell_type":"code","source":["n_rows = 3\nn_cols = 3\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(14,14))\n\ni = 0\nfor c in sorted(CATEGORICAL_FEATURES):\n    tmp_data = pd.crosstab(bank_pdf.loc[:, c], bank_pdf[TARGET_VARIABLE])\n    # pandas.crosstab returns an mxn table where m is the number of values for the first argument (x) \n    # and n for the second argument (y)\n    # As the second argument is always `TARGET_VARIABLE` (i.e., `deposit`), n = 2 (`deposit` is binary!)\n    # e.g., x = 'housing'; y = 'deposit'\n    # the following apply is used to transform the crosstab into a \"normalized\" table as follows:\n    # each entry in the table displays how the i-th categorical value of x (i.e., i-th row) is distributed across\n    # all the possible values of y (i.e., Y/N)\n    tmp_data = tmp_data.apply(lambda x: x/tmp_data.sum(axis=1))\n    ax = tmp_data.plot.bar(stacked=True, color=['red','green'], grid=False, ax=axes[i//n_cols, i % n_cols], legend=True)\n    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n    i += 1\n\nfig.tight_layout(pad=1.5)"],"metadata":{"id":"SAJ-CjTzmpQc","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31e3d225-37bd-4b06-a8a7-080bb028ba6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **3. The Learning Pipeline**"],"metadata":{"id":"66pFGdch-BU_","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e34b4673-92fc-4b1d-8d7e-75ea48c7ca33"}}},{"cell_type":"markdown","source":["### **Balanced vs. Unbalanced Dataset**\n\nSo far, we haven't looked at how the binary target variable `deposit` is distributed across the instances of our dataset. In this \"lucky\" example, we know that _positive_ examples (i.e., instances where `deposit = 1`) and _negative_ examples (i.e., instances where `deposit = 0`) are somehow balanced (i.e., around 50% of the instances are positives and the other 50% are negatives). That is due to the way this sample dataset has been extracted from the original one.\n\nMost often, though, we have to deal with (very) unbalanced datasets where the minority class (which is usually the one we are interested in!) is accounting only for a small fraction of the total number of training instances. For example, consider the click-through rate (CTR) prediction problem, where we want to foresee whether an advertisement (or, in general, a web page) will be clicked by a user. There, most of the advertisements will not be clicked (negatives), whilst only a tiny fraction (even smaller than 1%) of them will be.\n\nThe fact that a dataset is balanced (respectively, unbalanced) affects the process which we should use to correctly splitting it into _training_ and _test_ set. In particular:\n\n- If the dataset is (almost) balanced, we can safely use a **simple random sampling** strategy, which assigns to every instance the same probability of being selected (i.e., if there are _m_ instances, each one will be picked with the same uniform probability _p = 1/m_);\n- If the dataset is (very) unbalanced, simple random sampling might lead to a poor splitting strategy, where - for instance - the test set ends up containing only examples that are labeled with the most representative class. To overcome such an issue, **stratified random sampling** is the right choice to take as it guarantees that both the training and the test split follow the same class distribution observed in the original dataset (e.g., if the dataset contains 99% of negative instances and 1% of positive ones, so will the training and the test set). This works by first \"stratifying\" the data according to the two groups (i.e., positives vs. negatives), and within each group apply simple random sampling. For example, if our original dataset contains _m_ instances so that _m_ = (_m+_) + (_m-_) and _m+ << _m- (e.g., _m+_/_m_ = 0.01) and we want to sample _k_ < _m_ instances out of the dataset, we will first stratify the original dataset and will select _k+_ = _km+_/_m_ positive instances and _k-_ = _km-_/_m_ negative instances, respectively."],"metadata":{"id":"w4-GszAFNmSc","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f08bc60-b118-4b9c-b22e-d2dd7e0a75a0"}}},{"cell_type":"markdown","source":["### Let's first verify our dataset is actually _balanced_"],"metadata":{"id":"pbBHU28yS36r","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1eb69cf4-2e2b-4282-856e-fae99f0f4022"}}},{"cell_type":"code","source":["bank_df.groupBy(TARGET_VARIABLE).count().show()"],"metadata":{"id":"kF1A7XAsS911","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60054529-f3c1-41bc-a2a4-bb303f9623ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Dataset Splitting: Training vs. Test Set**\n\nBefore moving along with any preprocessing involving data transformations, we will split our dataset into **2** portions:\n- _training set_ (e.g., accounting for **80%** of the total number of instances);\n- _test set_ (e.g., accounting for the remaining **20%** of instances)"],"metadata":{"colab_type":"text","id":"xlUz0-TNb4Jo","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"139d375b-bd9d-4030-b79f-347f2bc6ac9d"}}},{"cell_type":"code","source":["RANDOM_SEED = 42"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f784741-1ba1-408f-80ff-6b1da6771b86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Randomly split our original dataset `house_df` into 80÷20 for training and test, respectively\ntrain_df, test_df = bank_df.randomSplit([0.8, 0.2], seed=RANDOM_SEED)"],"metadata":{"id":"ZSzZLA9QcA_P","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13947cda-c30c-45fc-8ed7-fdec2686ad5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Training set size: {:d} instances\".format(train_df.count()))\nprint(\"Test set size: {:d} instances\".format(test_df.count()))"],"metadata":{"id":"IRIWWJnJLo7g","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cbe3ce7-30ff-4765-988a-ab93cafb1823"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Working on the Training Set only**\n\nFrom now on, we will be working on the training set portion only. The test set will come back into play when we evaluate our learned model."],"metadata":{"id":"Kh179KdCcS81","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ad4a1fb-cd49-4eb3-ae72-4aecf03559cf"}}},{"cell_type":"markdown","source":["### **Transform Categorical features into Numerical using One-Hot Encoding**\n\nNote that this step is not always mandatory (e.g., decision trees are able to work nicely with categorical features without the need of transforming them to numerical). Still, other methods (like logistic regression) are designed to operate with numerical inputs only.\n\nTo transform _categorical_ features into _numerical_ ones we proceed as follows.\nWe setup a pipeline which is composed of the following steps:\n- [`StringIndexer`](https://spark.apache.org/docs/latest/ml-features#stringindexer): encodes a string column of labels to a column of label indices. The indices are in `[0, numLabels)`, and 4 ordering options are supported (default `frequencyDesc`, which assigns the most frequent label the index `0`, and so on and so forth).\n- [`OneHotEncoderEstimator`](https://spark.apache.org/docs/latest/ml-features#onehotencoderestimator): maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. An important parameter is `handleInvalid`, which indicates how to deal with previously unseen labels. By default this raises an error but it can be set to as `keep` to assign previously unseen labels a fallback value.\n- [`VectorAssembler`](https://spark.apache.org/docs/latest/ml-features#vectorassembler): is a transformer that combines a given list of columns into a single vector column."],"metadata":{"id":"11HcGwvdg90A","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"886c559b-8ac5-4243-a9c0-db8acd08fb75"}}},{"cell_type":"code","source":["# This function is responsible to implement the pipeline above for transforming categorical features into numerical ones\ndef to_numerical(df, numerical_features, categorical_features, target_variable):\n\n    \"\"\"\n    Args:\n        - df: the input dataframe\n        - numerical_features: the list of column names in `df` corresponding to numerical features\n        - categorical_features: the list of column names in `df` corresponding to categorical features\n        - target_variable: the column name in `df` corresponding to the target variable\n\n    Return:\n        - transformer: the pipeline of transformation fit to `df` (for future usage)\n        - df_transformed: the dataframe transformed according to the pipeline\n    \"\"\"\n    \n    from pyspark.ml import Pipeline\n    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n\n\n    # 1. Create a list of indexers, i.e., one for each categorical feature\n    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n\n    # 2. Create the one-hot encoder for the list of features just indexed (this encoder will keep any unseen label in the future)\n    encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers], \n                                    outputCols=[\"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers], \n                                    handleInvalid=\"keep\")\n\n    # 3. Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n    \n    # 4. Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n    assembler = VectorAssembler(inputCols=encoder.getOutputCols() + numerical_features, outputCol=\"features\")\n\n    # 5. Populate the stages of the pipeline\n    stages = indexers + [encoder] + [label_indexer] + [assembler]\n\n    # 6. Setup the pipeline with the stages above\n    pipeline = Pipeline(stages=stages)\n\n    # 7. Transform the input dataframe accordingly\n    transformer = pipeline.fit(df)\n    df_transformed = transformer.transform(df)\n\n    # 8. Eventually, return both the transformed dataframe and the transformer object for future transformations\n    return transformer, df_transformed "],"metadata":{"id":"BEHqXC-yvTft","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca0bd52f-010d-4e79-83b1-8ff7fef78c94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Remove `duration` from the list of NUMERICAL_FEATURES\nNUMERICAL_FEATURES.remove(\"duration\")\nprint(\"Removing `duration` from the set of numerical features: [{:s}]\".format(\", \".join([nf for nf in NUMERICAL_FEATURES])))"],"metadata":{"id":"uPaamUYtJh-0","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc0d4131-bd76-4c7e-b89c-c3b1accbb2bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":[" # Transform the training set and get back both the transformer and the new dataset\noh_transformer, oh_train_df = to_numerical(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"],"metadata":{"id":"ueRiKbiTxJsr","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f5f72f3-eb9a-45cf-8880-02aa079bfb41"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Show the result of numerical transformation\noh_train_df.show(5)"],"metadata":{"id":"vTix1SBg71Xr","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"589c5954-45a9-477c-ad4f-c6c1de692dd8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select `features` and `label` (i.e., formerly `deposit`) target variable only\ntrain = oh_train_df.select([\"features\", \"label\"])"],"metadata":{"id":"yYpzQRWqyxUx","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f83bda61-98fb-4c91-bdb6-5f3cc0a8ca40"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train.show(5, truncate=False)"],"metadata":{"id":"K2pZg_Pey-yP","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbad5b43-cac1-4679-a5dd-8d2c48c24cea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **Logistic Regression**\n\nWe first train a logistic regression model, using the training set above. To do so, we use the `LogisticRegression` object provided by the [PySpark API](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression) within the package `pyspark.ml.classification`.\n\nThe API is similar to the one we have seen for Linear Regression (i.e., implementing the **Elastic Net** regularization framework), except for the loss function which now is **cross-entropy** rather than **mean squared error**:\n$$\n\\boldsymbol{\\theta}^* = \\text{argmin}_{\\boldsymbol{\\theta}\\in \\mathbb{R}^n} \\frac{1}{m} \\sum_{i=1}^m \\log_e(1 + e^{-y_i\\boldsymbol{\\theta}^T\\mathbf{x}_i}) + \\lambda\\Big(\\alpha |\\boldsymbol{\\theta}| + (1-\\alpha)||\\boldsymbol{\\theta}||^2\\Big)\n$$\nIn particular, we can specify the following parameters:\n\n- `regParam` is the regularization parameter (or $\\lambda$);\n- `elasticNetParam` is the tradeoff parameter for regularization penalties (or $\\alpha$);\n  - `regParam = 0` and `elasticNetParam = 0` means there is no regularization;\n  - `regParam > 0` and `elasticNetParam = 0` means there is only L2-regularization; \n  - `regParam > 0` and `elasticNetParam = 1` means there is only L1-regularization;\n  - `regParam > 0` and `0 < elasticNetParam < 1` means there is both L1- and L2-regularization (Elastic Net);\n\nAs it is always the case, the optimal values of those **hyperparameters** should be tuned using a dedicated portion of the dataset (i.e., **validation set**) or by performing $k$**-fold cross validation**.\n\n**A Note on the Optimizer**\n\nSpark implements two algorithms to solve logistic regression: **Mini-Batch Gradient Descent** ([`pyspark.mllib.classification.LogisticRegressionWithSGD`](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=logisticregressionwithsgd)) and **L-BFGS** ([`pyspark.mllib.classification.LogisticRegressionWithLBFGS`](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=logisticregressionwithlbfgs)). By default, it uses (and recommends) L-BFGS as it generally converges faster than gradient descent due to the fact that it is a **second-order** optimization method (as opposed to **first-order** like gradient descent)."],"metadata":{"id":"teSVf-WFzvs-","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d1a3c20-f274-4514-9845-2672107fca95"}}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression # This corresponds to LogisticRegressionWithLBFGS\n\n# This setting corresponds to no regularization at all (i.e., both regParam=0 and elasticNetParam=0)\nlog_reg = LogisticRegression(featuresCol = \"features\", labelCol = \"label\", maxIter=100)\nlog_reg_model = log_reg.fit(train)"],"metadata":{"id":"Mmgq2uMK0AMF","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f02ea437-b084-4e43-a1b8-804640fdb26a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Intercept ($\\theta_0$) and Coefficients ($\\theta_1, \\ldots, \\theta_n$)**"],"metadata":{"id":"vf8I0bal0hsi","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4badc5b5-105e-4fc0-9a36-31a875415d18"}}},{"cell_type":"code","source":["print(\"Intercept: {:.5f}\".format(log_reg_model.intercept))\nprint(\"{:d} Coefficients: [{:s}]\".format(len(log_reg_model.coefficients), \",\".join([\"{:.3f}\".format(c) for c in log_reg_model.coefficients])))"],"metadata":{"id":"NyWx968q0zdk","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c975b0e6-fdab-4868-b995-68268fe1540e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Plot Coefficients**"],"metadata":{"id":"FfoJ6ySZIj-T","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efd0e7a1-f84b-43a2-8c2e-c27bb97fd1b1"}}},{"cell_type":"code","source":["theta = np.sort(log_reg_model.coefficients)\n\nfig, ax = plt.subplots(1, 1, figsize=(8,6))\n_ = sns.lineplot(x=range(0,len(log_reg_model.coefficients)), y=theta, marker=\"o\", axes=ax)\n_ = ax.set_xlabel(\"Theta Index\", labelpad=20)\n_ = ax.set_ylabel(\"Theta Value (log odds)\", labelpad=20)"],"metadata":{"id":"2B0LFPBAIdI_","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f58eb0f3-dcdc-4e12-ba8f-5ea02e411282"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Summarize model performance on the Training Set**"],"metadata":{"id":"_QEPpDoV1JnK","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92b40740-89b6-42a0-baef-0082e4447f0b"}}},{"cell_type":"code","source":["# Collect training summary\ntraining_summary = log_reg_model.summary"],"metadata":{"id":"J_euzi5eVpEj","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30d55c0f-dee5-44e5-91ea-414b0805d342"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### **Precision vs. Recall**"],"metadata":{"id":"hwMYv9wBVgU-","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e7daca3-82fa-4942-9cf1-c4ab1bbc9d99"}}},{"cell_type":"code","source":["precision_recall = training_summary.pr.toPandas()\n\nfig, ax = plt.subplots(1, 1, figsize=(8,6))\n_ = sns.lineplot(x=precision_recall['recall'], y=precision_recall['precision'], marker=\"s\", axes=ax)\n_ = ax.set_xlabel(\"Recall\", labelpad=20)\n_ = ax.set_ylabel(\"Precision\", labelpad=20)\n_ = ax.set_title(\"Precision vs. Recall\")"],"metadata":{"id":"ihYAjdDSVnHq","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a198c26-1bd0-45ce-bc4a-88be5cafe16e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### **Receiver-Operating Characteristic (ROC) and Area Under the ROC (AUC)**"],"metadata":{"id":"i7HfPpUAVdva","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2d1439b-2e15-4f3e-9910-4b4d2dd80fc4"}}},{"cell_type":"code","source":["roc = training_summary.roc.toPandas()\n\nfig, ax = plt.subplots(1, 1, figsize=(8,6))\n_ = sns.lineplot(x=roc['FPR'], y=roc['TPR'], marker=\"s\", axes=ax)\n_ = ax.set_xlabel(\"False Positive Rate\", labelpad=20)\n_ = ax.set_ylabel(\"True Positive Rate\", labelpad=20)\n_ = ax.set_title(\"ROC Curve\")"],"metadata":{"id":"OsID3E0r07i5","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34e022fd-cd1e-4f6c-b33a-9ae0fd9b815f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Print out the Area Under the ROC Curve (AUC)\nprint('Training Set AUC: {:.3f}'.format(training_summary.areaUnderROC))"],"metadata":{"id":"T41l1yFIQ78g","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e41d4d1e-2ae1-4f6d-91bb-e907c7aecb58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Use the One-Hot encoding pipeline to transform the Test Set**"],"metadata":{"id":"ena6EJ0Y5qhx","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"378c6318-209b-4452-8f82-9f5598613047"}}},{"cell_type":"code","source":["# Here, we use the same transformer as the one returned by the `to_numerical` function above yet applied to the test set\noh_test_df = oh_transformer.transform(test_df)"],"metadata":{"id":"KPgeFLQC1S1t","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34006e1b-f705-43c9-bcd4-a2e98e5fc3c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["oh_test_df.show(5)"],"metadata":{"id":"YoU_fGuA2ivF","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb838a92-c61b-4b31-9d16-23b48c772cda"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select `features` and `label` only\ntest = oh_test_df.select([\"features\", \"label\"])\ntest.show(5)"],"metadata":{"id":"oMNJ1NdtwXB8","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b8f417a-d491-46ce-86ea-96f8de892af2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Compute predictions on the Test Set according to the model learned on the Training Set**"],"metadata":{"id":"LokzdSNP6T48","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beff813b-cb78-4ea6-b478-e6e6c5103110"}}},{"cell_type":"code","source":["# `log_reg_model` is a Transformer which can be used to \"transform\" our test set\npredictions = log_reg_model.transform(test)"],"metadata":{"id":"Y-tiLfEA1tml","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a57d2a3-6cb6-48f3-8bd5-53d241fb8872"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# `predictions` is a dataframe containing (among other things) the predictions made by `log_reg_model` on the test set\npredictions.select(\"features\", \"prediction\", \"label\").show(10)"],"metadata":{"id":"KjjN-q_dw8CA","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b71bcfd8-81d1-4bc8-916d-d8f4a9b231de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Evaluate model performance on the Test Set**"],"metadata":{"id":"9fue7UUz5mom","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bf7a75a-1900-470e-b015-17b5f5960936"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint('Test Set AUC: {:.3f}'.format(evaluator.evaluate(predictions)))"],"metadata":{"id":"0GySC6TS5c_i","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c05db2c-63f1-4073-92bb-65dee45e40f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## **Tuning Hyperparameters**\n\nIn the following, we try to summarize the whole pipeline making use also of $k$-fold cross validation to get a better estimate of the generalization performance of our logistic regression model.\n\nMore specifically, we will tune the two hyperparameters: $\\lambda$ = `regParam` and $\\alpha$ = `elasticNetParam`."],"metadata":{"id":"mKWC5LfR6ibL","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"706575d9-e8f6-4fce-a85d-3de8fdaf04ce"}}},{"cell_type":"code","source":["# This function defines the general pipeline for logistic regression\ndef logistic_regression_pipeline(train, \n                                 numerical_features, \n                                 categorical_features, \n                                 target_variable, \n                                 with_std=True,\n                                 with_mean=True,\n                                 k_fold=5):\n\n    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n    from pyspark.ml.classification import LogisticRegression\n    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n    from pyspark.ml import Pipeline\n\n    # Configure a logistic regression pipeline, which consists of the following stages: \n    # 1) convert categorical features to numerical ones\n    # 2) standardize feature values (optional)\n    # ... add any other custom transformation here ...\n    # n) fit a logistic regression model\n\n\n    # 1.a Create a list of indexers, i.e., one for each categorical feature\n    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n\n    # 1.b Create the one-hot encoder for the list of features just indexed (this encoder will keep any unseen label in the future)\n    encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers], \n                                    outputCols=[\"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers], \n                                    handleInvalid=\"keep\")\n\n    # 1.c Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n    \n    # 1.d Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n    assembler = VectorAssembler(inputCols=encoder.getOutputCols() + numerical_features, outputCol=\"features\")\n\n    # 2.a Create the StandardScaler\n    # scaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"std_\"+assembler.getOutputCol(), withStd=with_std, withMean=with_mean)\n    # ...\n\n    # 3 Populate the stages of the pipeline with all the preprocessing steps\n    stages = indexers + [encoder] + [label_indexer] + [assembler] # + [scaler] + ...\n\n    # 4. Create the logistic regression transformer\n    log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100) # change `featuresCol=std_features` if scaler is used\n\n    # 5. Add the logistic regression transformer to the pipeline stages (i.e., the last one)\n    stages += [log_reg]\n\n    # 6. Set up the pipeline\n    pipeline = Pipeline(stages=stages)\n\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # With 3 values for log_reg.regParam ($\\lambda$) and 3 values for log_reg.elasticNetParam ($\\alpha$),\n    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n    param_grid = ParamGridBuilder()\\\n    .addGrid(log_reg.regParam, [0.0, 0.05, 0.1]) \\\n    .addGrid(log_reg.elasticNetParam, [0.0, 0.5, 1.0]) \\\n    .build()\n    \n    cross_val = CrossValidator(estimator=pipeline, \n                               estimatorParamMaps=param_grid,\n                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                               numFolds=k_fold,\n                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n                               )\n\n    # Run cross-validation, and choose the best set of parameters.\n    cv_model = cross_val.fit(train)\n\n    return cv_model"],"metadata":{"id":"Ux02QmTg7_Ps","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6b718db-75f1-41aa-8a32-35f145f25d81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["cv_model = logistic_regression_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"],"metadata":{"id":"xjnj2jXeRSEJ","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"471b3194-293a-4828-b998-cdf9a6955699"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# This function summarizes all the models trained during k-fold cross validation\ndef summarize_all_models(cv_models):\n    for k, models in enumerate(cv_models):\n        print(\"*************** Fold #{:d} ***************\\n\".format(k+1))\n        for i, m in enumerate(models):\n            print(\"--- Model #{:d} out of {:d} ---\".format(i+1, len(models)))\n            print(\"\\tParameters: lambda=[{:.3f}]; alpha=[{:.3f}] \".format(m.stages[-1]._java_obj.getRegParam(), m.stages[-1]._java_obj.getElasticNetParam()))\n            print(\"\\tModel summary: {}\\n\".format(m.stages[-1]))\n        print(\"***************************************\\n\")"],"metadata":{"id":"IHvPkEyEBUOf","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6207b31b-5fff-45f8-9e16-aa16c630820b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Call the function above|\nsummarize_all_models(cv_model.subModels)"],"metadata":{"id":"m50kfzDTRhsd","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5cf361ed-9d59-4561-aa3e-847f2b86350e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"],"metadata":{"id":"jJyI7BSC8cmA","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a2111eb-e101-4e22-9974-11679aeef292"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Best model according to k-fold cross validation: lambda=[{:.3f}]; alfa=[{:.3f}]\".\n      format(cv_model.bestModel.stages[-1]._java_obj.getRegParam(), \n             cv_model.bestModel.stages[-1]._java_obj.getElasticNetParam(),\n             )\n      )\nprint(cv_model.bestModel.stages[-1])"],"metadata":{"id":"sg_ockQBQjNX","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ce4ce0f-c188-4b55-87de-2839a9464db3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Summarize model performance on the Training Set**"],"metadata":{"id":"BzVrvU9kJOZj","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3814c7d-1502-46fa-a19e-581175dace8a"}}},{"cell_type":"code","source":["# `bestModel` is the best resulting model according to k-fold cross validation, which is also entirely retrained on the whole `train_df`\ntraining_result = cv_model.bestModel.stages[-1].summary\nprint(\"***** Training Set *****\")\nprint(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(training_result.areaUnderROC))\nprint(\"***** Training Set *****\")"],"metadata":{"id":"fLgNpJP0JVtw","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d2f2011-7223-4d71-a6db-2cda6f1bc364"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Using the best model from $k$-fold cross validation to make predictions**"],"metadata":{"id":"yadIWG4pIcrr","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08defae7-75b0-44de-8979-2bbde9d44816"}}},{"cell_type":"code","source":["# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions = cv_model.transform(test_df)"],"metadata":{"id":"b01W9KqbSz6c","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1351a19-0bae-4518-b7de-641c3d2fe0c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"],"metadata":{"id":"2Tlh8G3STxGh","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d90947b9-eaf1-4366-817d-c576defeefdf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def evaluate_model(predictions, metric=\"areaUnderROC\"):\n    \n    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n    evaluator = BinaryClassificationEvaluator(metricName=metric)\n\n    return evaluator.evaluate(predictions)"],"metadata":{"id":"FOA-EKGxU16J","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"493985a6-1e21-467b-bae9-fdcef2c6580e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Evaluate model performance on the Test Set**"],"metadata":{"id":"7ulP5vi_VpnP","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"536fd28b-818a-4974-8be8-f941437738c2"}}},{"cell_type":"code","source":["print(\"***** Test Set *****\")\nprint(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\nprint(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\nprint(\"***** Test Set *****\")"],"metadata":{"id":"WDEu2HuaaueC","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afc2c20e-2581-4126-bde0-38271c3cd150"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# **Decision Tree**\n\nWe now train a decision tree (i.e., classification tree), using the training set above. Remember that decision trees natively handle categorical features, extend to the multi-class classification, do not require feature scaling, and are able to capture non-linearities and feature interactions.\n\nWe will use the `DecisionTreeClassifier` object provided by the [PySpark API](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier) within the package `pyspark.ml.classification`."],"metadata":{"id":"JrzGDwgj8d9x","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e0e53f2-ce59-4d3a-92d2-5faf789abd4f"}}},{"cell_type":"code","source":["# This function defines the general pipeline for logistic regression\ndef decision_tree_pipeline(train, \n                           numerical_features, \n                           categorical_features, \n                           target_variable, \n                           with_std=True,\n                           with_mean=True,\n                           k_fold=5):\n\n    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n    from pyspark.ml.classification import DecisionTreeClassifier\n    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n    from pyspark.ml import Pipeline\n\n    # Configure a decision tree pipeline, which consists of the following stages: \n\n    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n\n    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n    \n    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n\n    # Populate the stages of the pipeline with all the preprocessing steps\n    stages = indexers + [label_indexer] + [assembler] # + ...\n\n    # Create the decision tree transformer\n    dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n\n    # 5. Add the decision tree transformer to the pipeline stages (i.e., the last one)\n    stages += [dt]\n\n    # 6. Set up the pipeline\n    pipeline = Pipeline(stages=stages)\n\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # With 3 values for dt.maxDepth and 2 values for dt.impurity\n    # this grid will have 3 x 2 = 9 parameter settings for CrossValidator to choose from.\n    param_grid = ParamGridBuilder()\\\n    .addGrid(dt.maxDepth, [3, 5, 8]) \\\n    .addGrid(dt.impurity, [\"gini\", \"entropy\"]) \\\n    .build()\n    \n    cross_val = CrossValidator(estimator=pipeline, \n                               estimatorParamMaps=param_grid,\n                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                               numFolds=k_fold,\n                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n                               )\n\n    # Run cross-validation, and choose the best set of parameters.\n    cv_model = cross_val.fit(train)\n\n    return cv_model"],"metadata":{"id":"25AZUOQP8dRW","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7017ac2-e1e2-4d35-9677-98a7f38b3e16"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["cv_model = decision_tree_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"],"metadata":{"id":"0yt2Cdm6F5E6","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec7caf1a-12f5-4be7-8f18-13a348f6e41e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# This function summarizes all the models trained during k-fold cross validation\n\ndef summarize_all_models(cv_models):\n    for k, models in enumerate(cv_models):\n        print(\"*************** Fold #{:d} ***************\\n\".format(k+1))\n        for i, m in enumerate(models):\n            print(\"--- Model #{:d} out of {:d} ---\".format(i+1, len(models)))\n            print(\"\\tParameters: maxDept=[{:d}]; impurity=[{:s}] \".format(m.stages[-1]._java_obj.getMaxDepth(), m.stages[-1]._java_obj.getImpurity()))\n            print(\"\\tModel summary: {}\\n\".format(m.stages[-1]))\n        print(\"***************************************\\n\")"],"metadata":{"id":"ghCWiKI5JS68","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d4444bd-97be-438b-a752-9d53590ce08c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["summarize_all_models(cv_model.subModels)"],"metadata":{"id":"U-ApTiF_JZOf","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff2fbf24-46b1-4ca7-a771-705ea6eadd94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"],"metadata":{"id":"unM_AG88XauX","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2ef83af-c56e-4d44-923b-b8767c2c9979"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Best model according to k-fold cross validation: maxDept=[{:d}]; impurity=[{:s}]\".\n      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n             cv_model.bestModel.stages[-1]._java_obj.getImpurity(),\n             )\n      )\nprint(cv_model.bestModel.stages[-1])"],"metadata":{"id":"gDmOgLrXPRJ0","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"571e3297-8145-446f-be90-4966cc639e25"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Using the best model from $k$-fold cross validation to make predictions**"],"metadata":{"colab_type":"text","id":"-NQVcLGDNplX","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2105bf38-01d0-4e82-8447-f3bda2f7f284"}}},{"cell_type":"code","source":["# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions = cv_model.transform(test_df)"],"metadata":{"colab_type":"code","id":"aK-n0LceNplY","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"901fce16-f932-4057-abf0-9e572ced7b36"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"],"metadata":{"colab_type":"code","id":"haSPSR2bNpla","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebc04d0b-4c08-4b57-a749-533a7801ee1c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Evaluate model performance on the Test Set**"],"metadata":{"colab_type":"text","id":"TjhSbqlPNple","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba8136d9-75b5-44a6-8283-0a208e5e332d"}}},{"cell_type":"code","source":["print(\"***** Test Set *****\")\nprint(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\nprint(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\nprint(\"***** Test Set *****\")"],"metadata":{"colab_type":"code","id":"am6H-UvlNple","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"497c53cb-286a-4d6c-8a0e-b19c459c8b36"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## **Observations**\n\nAs it turns out, one simple decision tree performed worst than logistic regression because it is too weak given the range of different features (ROC AUC = 0.556 vs. 0.764, respectively). The prediction accuracy of decision trees can be improved by ensemble methods, such as **Random Forests** (**RF**) and **Gradient Boosted Decision Trees** (**GBDT**)."],"metadata":{"id":"YlZQURklPG_9","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56e4363b-288c-4c4e-90e1-786c4d00d018"}}},{"cell_type":"markdown","source":["# **Random Forests**"],"metadata":{"id":"H5WxSDJBRDNM","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6e07dde-646e-4330-a54c-e8151f0c0225"}}},{"cell_type":"code","source":["# This function defines the general pipeline for logistic regression\ndef random_forest_pipeline(train, \n                           numerical_features, \n                           categorical_features, \n                           target_variable, \n                           with_std=True,\n                           with_mean=True,\n                           k_fold=5):\n\n    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n    from pyspark.ml.classification import RandomForestClassifier\n    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n    from pyspark.ml import Pipeline\n\n    # Configure a random forest pipeline, which consists of the following stages: \n\n    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n\n    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n    \n    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n\n    # Populate the stages of the pipeline with all the preprocessing steps\n    stages = indexers + [label_indexer] + [assembler] # + ...\n\n    # Create the random forest transformer\n    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n\n    # 5. Add the random forest transformer to the pipeline stages (i.e., the last one)\n    stages += [rf]\n\n    # 6. Set up the pipeline\n    pipeline = Pipeline(stages=stages)\n\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # With 3 values for rf.maxDepth and 3 values for rf.numTrees\n    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n    param_grid = ParamGridBuilder()\\\n    .addGrid(rf.maxDepth, [3, 5, 8]) \\\n    .addGrid(rf.numTrees, [10, 50, 100]) \\\n    .build()\n    \n    cross_val = CrossValidator(estimator=pipeline, \n                               estimatorParamMaps=param_grid,\n                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                               numFolds=k_fold,\n                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n                               )\n\n    # Run cross-validation, and choose the best set of parameters.\n    cv_model = cross_val.fit(train)\n\n    return cv_model"],"metadata":{"id":"NvPi4wwwRFwp","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de1466c1-362f-480b-b247-08799586f9bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["cv_model = random_forest_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"],"metadata":{"id":"5Ch6K6w6SH1n","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bdd8c24-c82d-4c77-b578-05cff03c25e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"],"metadata":{"id":"OY_1PB55Y0rJ","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfce2f76-07f9-4f10-a286-22e08b0d7213"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Best model according to k-fold cross validation: maxDept=[{:d}]\".\n      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n             )\n      )\nprint(cv_model.bestModel.stages[-1])"],"metadata":{"id":"e2PjmxpqSM5r","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"451b4e87-260b-4358-bc01-5efe91401f6b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Using the best model from $k$-fold cross validation to make predictions**"],"metadata":{"colab_type":"text","id":"RUhN4Kv_TD0b","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7838e51-43e4-4752-86ef-8defb006c2de"}}},{"cell_type":"code","source":["# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions = cv_model.transform(test_df)"],"metadata":{"colab_type":"code","id":"zfqhpoelTD0e","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7e2feaf-700b-482a-9e74-901cd17e1a04"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"],"metadata":{"colab_type":"code","id":"TEovQrlHTD0h","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"898eb05f-2711-46b7-83dc-4077b9b24678"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Evaluate model performance on the Test Set**"],"metadata":{"colab_type":"text","id":"JFKKUoUfTD0k","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b11a03d6-c2e7-49ba-8c4d-7ef9f4bdcc6b"}}},{"cell_type":"code","source":["print(\"***** Test Set *****\")\nprint(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\nprint(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\nprint(\"***** Test Set *****\")"],"metadata":{"colab_type":"code","id":"d3enTDtzTD0l","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8e31b39-5592-4c25-aa27-b4be300bdb7f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## **Observations**\n\nUsing Random Forest we are able to improve ROC AUC to **0.789** from 0.556 of a single decision tree! Let's see if we can do even better using GBDT."],"metadata":{"id":"KI-3MJe_UDPt","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb007dd5-3aea-43a9-b7c5-a837fcb3d0f2"}}},{"cell_type":"markdown","source":["# **Gradient Boosted Decision Tree**"],"metadata":{"id":"Tols6SZpTTL9","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"408f2bad-5e71-4d6b-8b9f-da03f07a0c0a"}}},{"cell_type":"code","source":["# This function defines the general pipeline for logistic regression\ndef gbdt_pipeline(train, \n                           numerical_features, \n                           categorical_features, \n                           target_variable, \n                           with_std=True,\n                           with_mean=True,\n                           k_fold=5):\n\n    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n    from pyspark.ml.classification import GBTClassifier\n    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n    from pyspark.ml import Pipeline\n\n    # Configure a gradient boosted decision tree pipeline, which consists of the following stages: \n\n    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n\n    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n    \n    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n\n    # Populate the stages of the pipeline with all the preprocessing steps\n    stages = indexers + [label_indexer] + [assembler] # + ...\n\n    # Create the gradient boosted decision tree transformer\n    gbdt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n\n    # 5. Add the gradient boosted decision tree transformer to the pipeline stages (i.e., the last one)\n    stages += [gbdt]\n\n    # 6. Set up the pipeline\n    pipeline = Pipeline(stages=stages)\n\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n    # With 3 values for gbdt.maxDepth and 3 values for gbdt.maxIter (i.e., boosting rounds)\n    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n    param_grid = ParamGridBuilder()\\\n    .addGrid(gbdt.maxDepth, [3, 5, 8]) \\\n    .addGrid(gbdt.maxIter, [10, 50, 100]) \\\n    .build()\n    \n    cross_val = CrossValidator(estimator=pipeline, \n                               estimatorParamMaps=param_grid,\n                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n                               numFolds=k_fold,\n                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n                               )\n\n    # Run cross-validation, and choose the best set of parameters.\n    cv_model = cross_val.fit(train)\n\n    return cv_model"],"metadata":{"id":"qQwO_EeRTzjk","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6995daf9-e817-41d5-a5d5-ef68e834718d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["cv_model = gbdt_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"],"metadata":{"id":"oTAMWchwUx3_","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6d9169d-c5b4-4c75-84c3-241cc42af817"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"],"metadata":{"id":"RKJQZlEeY9U9","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68b50c82-69af-4cb0-9a4a-b5494073b492"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Best model according to k-fold cross validation: maxDept=[{:d}]; maxIter=[{:d}]\".\n      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n             cv_model.bestModel.stages[-1]._java_obj.getMaxIter()\n             )\n      )\nprint(cv_model.bestModel.stages[-1])"],"metadata":{"id":"mslU-QwkU7hg","colab_type":"code","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2939fcb-c8a7-47e4-a2f3-82a840361999"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Using the best model from $k$-fold cross validation to make predictions**"],"metadata":{"colab_type":"text","id":"J3wedGS1XTKl","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0428da7-26bc-45d5-94bc-49423ece7571"}}},{"cell_type":"code","source":["# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\ntest_predictions = cv_model.transform(test_df)"],"metadata":{"colab_type":"code","id":"Ld5P-_CAXTKm","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f63ce404-1b70-4113-bb97-cba0156e9586"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"],"metadata":{"colab_type":"code","id":"OuZz4HF0XTKo","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"262049d0-6e7b-4fb8-8e9b-1626f05b1354"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### **Evaluate model performance on the Test Set**"],"metadata":{"colab_type":"text","id":"nmX-lvcgXTKs","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ff747cc-8f63-4138-971a-6a02dfd43ba2"}}},{"cell_type":"code","source":["print(\"***** Test Set *****\")\nprint(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\nprint(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\nprint(\"***** Test Set *****\")"],"metadata":{"colab_type":"code","id":"1Gyr1FYUXTKs","colab":{},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6629f02-9d57-4253-8461-6d92e3894768"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## **Final Remarks**\n\nGBDT has improved the value of ROC AUC previously obtained by Random Forest to **0.789**: this is the highest score obtained amongst all the models we have evaluated."],"metadata":{"id":"6T4xevfjcodJ","colab_type":"text","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"005a8c6a-341c-4f0a-9083-7af84edf49e5"}}}],"metadata":{"colab":{"name":"Lecture_10-11_Classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"application/vnd.databricks.v1+notebook":{"notebookName":"Classification","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3966539020232142}},"nbformat":4,"nbformat_minor":0}
